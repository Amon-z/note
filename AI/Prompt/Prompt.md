## 学习认知

- CRISPE框架
  - 上下文（Context）
  - 角色（Role）
  - 说明（Instruction）
  - 主题（Subject）
  - 预设（Preset）
  - 例外（Exception）
- BROKE框架
  - 阐述背景B（Background）
  - 定义角色R（Role）
  - 定义目标O（Objectives）
  - 定义关键结果K（Key Result）
  - 实验并改进E（Evolve）
- ICIP框架
  - Instruction（必须）：指令
  - Context（选填）：背景信息
  - Input Data（选填）：输入数据
  - Output Indicator（选填）：输出指示器

## 基础编写技巧

原理：补全

输出的随机性

输出的上限：token

- 使用明确且具体的指令
  - 使用分隔符
  - 检查特定的词汇
  - 明确输出要求
- 提供示例
  - 提供风格示例
  - 提供行为示例
  - 提供中间步骤示例
  - 提供条件判断示例

## 基础编写方法

强提示和弱提示，模型训练过程中学到过的提示，输出结果的确定性较高。

- 角色定义法
- 受众定义法
- 场景定义法
- 问题精炼法
  - 每当我提出一个问题时，建议我一个更好的问题，并询问我是否愿意使用它
- 问题拆解法
  - 问题x，生成一系列有助于更准确回答问题的附加问题，将答案组合产生最终答案。
- 请求输入法
  - 让ChatGPT不会立刻回答。{提示词}，现在，问我第一个问题。

## 按需设计并迭代

“若无必要，勿增实体”——奥卡姆剃刀原则，追求“简单有效“和”化简为繁“

好的提示词应该和代码一样，按需设计，易维护，不冗余。从一个核心需求开始，不断的调整和优化提示词，以达到当前可以接受的最佳效果。

- 精心选择信息，避免过度复杂
- 测试最少的提示词能否完成任务，确保核心部分稳定可靠
- 如有问题，逐步裁剪多余部分，以便更好地定位问题

设计易于维护的提示词

## 提示词常见误区

### 明确你和大模型说的是否是一回事

- 常见误区：
  - 认知上的差异：ai并不能知道人所处的情境
  - 对技术的误解：大模型并不能像人一样，缺乏背景信息的自然对话往往会让用户失望
  - 期望值过高：ai并不是无所不能

- 如何避免误区：
  - 明确提问
  - 提供上下文
  - 多次迭代
- ”概念对齐”：不确定模型和自己理解是否一致时
  - 不同方式重新提问再次确认
  - 使用例子进行验证
  - 提供详细的信息背景
  - 询问定义

### 许愿式提示词

- 许愿式提示词 X
  - 攥写爆款标题：爆款是一个极具主和时效性的词，其定义受不同文化、地域、时间、受众和渠道而异
  - 具有优美的文风：美是主观的没有标准的
  - 用细腻的笔触刻画人物：需要足够的信息填充人物才有可能

### 内容误导

- 内容误导
  - 立场预设，比如问大模型电影好看吗，是不是跟传闻的一样无聊，模型就会偏向负面评价
  - 引述和用户自己观点混淆，分隔词不明确
- 避免策略
  - 确保问题和提示词中立
  - 使用明确的分隔符

## 实战+变现案例



## 进阶-结构化



















